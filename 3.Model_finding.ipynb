{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd #pandas to create small dataframes \n",
    "import json         #json library would be using to parse JSON Columns\n",
    "from pandas.io.json import json_normalize #Library to normalize semi-structured JSON data into a flat table.\n",
    "import os           #Library to use system level variable.\n",
    "import matplotlib.pylab as plt #Plotting\n",
    "from matplotlib import pyplot\n",
    "import numpy as np  #Do aritmetic operations on arrays\n",
    "import plotly.graph_objects as go #Graphing library. \n",
    "import gc           #Garbage Collector interface\n",
    "gc.enable() #Enable automatic garbage collection.\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV #Hypertune parameters for model\n",
    "from datetime import datetime, timedelta #The datetime module supplies classes for manipulating dates and times.\n",
    "from sklearn import preprocessing #Will use this library to label encode categorical features.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer, confusion_matrix, fbeta_score, classification_report \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import *\n",
    "from scipy import stats\n",
    "import statsmodels.api as sms\n",
    "\n",
    "# Show all columns\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.read_csv(\"df_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X & Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = df_model.pop(\"y_class\")\n",
    "y_reg = df_model.pop('y_reg')\n",
    "X = df_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y_class,random_state=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model all zero\n",
    "y_baseline = np.zeros(len(y_test))\n",
    "#y_baseline = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94263,     0],\n",
       "       [   34,     0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_baseline)\n",
    "# TN, FP\n",
    "# FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00     94263\n",
      "        True       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           1.00     94297\n",
      "   macro avg       0.50      0.50      0.50     94297\n",
      "weighted avg       1.00      1.00      1.00     94297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alles Null\n",
    "print(classification_report(y_test,y_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.95444143075098"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy baseline\n",
    "(94341+0)/(94384)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DecTree = tree.DecisionTreeClassifier()\n",
    "model_DecTree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94263,     0],\n",
       "       [   34,     0]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94263,     0],\n",
       "       [   32,     2]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model with 100 trees\n",
    "model_rf = RandomForestClassifier(n_estimators=50,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "# Fit on training data\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred = model_rf.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)\n",
    "# TN, FP\n",
    "# FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00     94263\n",
      "        True       1.00      0.09      0.16        34\n",
      "\n",
      "    accuracy                           1.00     94297\n",
      "   macro avg       1.00      0.54      0.58     94297\n",
      "weighted avg       1.00      1.00      1.00     94297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Optimization through Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True],\n",
       "                                        'max_depth': [None],\n",
       "                                        'max_features': ['sqrt'],\n",
       "                                        'max_leaf_nodes': [None, 80, 86, 93,\n",
       "                                                           100],\n",
       "                                        'min_samples_split': [4, 5],\n",
       "                                        'n_estimators': array([250, 272, 294, 316, 338, 361, 383, 405, 427, 450])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=50, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': np.linspace(250, 450, 10).astype(int),\n",
    "    'max_depth': [None],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_leaf_nodes': [None]+ list(np.linspace(80, 100, 4).astype(int)),\n",
    "    'min_samples_split': [4,5],\n",
    "    'bootstrap': [True]\n",
    "}\n",
    "\n",
    "RSEED = 50\n",
    "\n",
    "# Estimator for use in random search\n",
    "estimator = RandomForestClassifier(random_state = RSEED)\n",
    "\n",
    "# Create the random search model\n",
    "rs = RandomizedSearchCV(estimator, param_grid, n_jobs = -1, \n",
    "                        scoring = 'roc_auc', cv = 3, \n",
    "                        n_iter = 10, verbose = 1, random_state=RSEED)\n",
    "\n",
    "# Fit \n",
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 450,\n",
       " 'min_samples_split': 5,\n",
       " 'max_leaf_nodes': 80,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best Params\n",
    "rs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Best Model\n",
    "best_model = rs.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)\n",
    "# TN, FP\n",
    "# FN, TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model to x\n",
    "model_xgb = XGBClassifier()\n",
    "model_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94261,     2],\n",
       "       [   30,     4]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_xgb.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)\n",
    "# TN, FP\n",
    "# FN, TP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost Optimization through GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_xgb = {'xgbclassifier__max_depth':[2, 3],\n",
    "                  'xgbclassifier__learning_rate':[0.1],\n",
    "                  'xgbclassifier__n_estimators':[3, 50],\n",
    "                  'xgbclassifier__booster':[\"gbtree\"],\n",
    "                  'xgbclassifier__gamma':[4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'xgbclassifier__booster': 'gbtree', 'xgbclassifier__gamma': 4, 'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__max_depth': 2, 'xgbclassifier__n_estimators': 3}\n"
     ]
    }
   ],
   "source": [
    "#f = 'gain'\n",
    "grid_xgb = GridSearchCV(model_xgb, param_grid_xgb, return_train_score=False,n_jobs=3)\n",
    "grid_xgb.fit(X_train, y_train)\n",
    "print(grid_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_GS=grid_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94261,     2],\n",
       "       [   30,     4]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_GS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svc = SVC()\n",
    "model_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94263,     0],\n",
       "       [   34,     0]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier()\n",
    "model_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94263,     0],\n",
       "       [   34,     0]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logit = LogisticRegression(max_iter=1000)\n",
    "model_logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94263,     0],\n",
       "       [   34,     0]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ada = AdaBoostClassifier()\n",
    "model_ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94263,     0],\n",
       "       [   34,     0]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,\n",
       "               importance_type='split', learning_rate=0.05, max_depth=-1,\n",
       "               max_leaves=250, metric='binary_logloss', min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=222,\n",
       "               n_jobs=-1, num_leaves=16, objective='binary', random_state=None,\n",
       "               reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=0.7,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metric = 'binary_logloss', \n",
    "model_lgb = lgb.LGBMClassifier(objective = 'binary',\n",
    "                               metric = 'binary_logloss',\n",
    "model_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94088,   175],\n",
       "       [   32,     2]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_lgb.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters to search\n",
    "gridParams = {\n",
    "    'learning_rate': [0.35],    \n",
    "    'n_estimators': [100,110],           \n",
    "    'num_leaves': [16],           \n",
    "    'boosting_type' : ['dart'],\n",
    "    'reg_alpha' : [1],                    \n",
    "    'reg_lambda' : [1],                   \n",
    "    'objective' : ['binary'],              \n",
    "    'metric' : ['binary_logloss'],        \n",
    "    'colsample_bytree' : [0.8],     \n",
    "    'subsample' : [0.7],             \n",
    "    'max_leaves': [100,105],           \n",
    "    'min_child_samples' : [18,20]            \n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define LightGBM Classifier model\n",
    "model_lgb_gs = lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=LGBMClassifier(boosting_type='gbdt',\n",
       "                                            class_weight=None,\n",
       "                                            colsample_bytree=1.0,\n",
       "                                            importance_type='split',\n",
       "                                            learning_rate=0.1, max_depth=-1,\n",
       "                                            min_child_samples=20,\n",
       "                                            min_child_weight=0.001,\n",
       "                                            min_split_gain=0.0,\n",
       "                                            n_estimators=100, n_jobs=-1,\n",
       "                                            num_leaves=31, objective=None,\n",
       "                                            random_state=None, reg_alpha=0.0,\n",
       "                                            reg_lambda=0.0, sile...\n",
       "                   param_distributions={'boosting_type': ['dart'],\n",
       "                                        'colsample_bytree': [0.8],\n",
       "                                        'learning_rate': [0.35],\n",
       "                                        'max_leaves': [100, 105],\n",
       "                                        'metric': ['binary_logloss'],\n",
       "                                        'min_child_samples': [18, 20],\n",
       "                                        'n_estimators': [100, 110],\n",
       "                                        'num_leaves': [16],\n",
       "                                        'objective': ['binary'],\n",
       "                                        'reg_alpha': [1], 'reg_lambda': [1],\n",
       "                                        'subsample': [0.7]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomizedSearchCV to hypertune the parameters\n",
    "randCV = RandomizedSearchCV(model_lgb_gs, gridParams,\n",
    "                    cv=3,\n",
    "                    n_jobs=1)\n",
    "\n",
    "# Fit \n",
    "randCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', class_weight=None, colsample_bytree=0.8,\n",
       "               importance_type='split', learning_rate=0.35, max_depth=-1,\n",
       "               max_leaves=100, metric='binary_logloss', min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "               n_jobs=-1, num_leaves=16, objective='binary', random_state=None,\n",
       "               reg_alpha=1, reg_lambda=1, silent=True, subsample=0.7,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_lgb = randCV.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94261,     2],\n",
       "       [   30,     4]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_model_lgb.predict(X_test)\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
